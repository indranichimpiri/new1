
# Import necessary libraries
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np

# Define the URL of the webpage to scrape
url = 'https://www.spaceweatherlive.com/en/solar-activity/top-50-solar-flares.html'

# Send an HTTP GET request to the URL
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    # Parse the HTML content of the page
    soup = BeautifulSoup(response.text, 'html.parser')

    # Find the table containing the top 50 solar flares data
    table = soup.find('table')

    # Create an empty list to store the data
    data = []

    # Loop through the rows of the table
    for row in table.find_all('tr')[1:]:  # Skip the header row
        cols = row.find_all('td')

        # Extract data from each column
        rank = cols[0].text.strip()
        x_classification = cols[1].text.strip()
        date = cols[2].text.strip()
        region = cols[3].text.strip()
        start_time = cols[4].text.strip()
        max_time = cols[5].text.strip()
        end_time = cols[6].text.strip()
        movie = cols[7].find('a')['href']  # Extract the link to the movie

        # Append the data to the list
        data.append([rank, x_classification, date, region, start_time, max_time, end_time, movie])

    # Create a DataFrame from the list of data
    columns = ['rank', 'x_classification', 'date', 'region', 'start_time', 'max_time', 'end_time', 'movie']
    df = pd.DataFrame(data, columns=columns)

    # Print the expected output format
    print("Dimension: 50 Ã— 8")
    print()
    print(df.to_string(index=False))

    # Save the DataFrame to a CSV file if needed
    # df.to_csv('solar_flares.csv', index=False)

else:
    print('Failed to retrieve the webpage.')

# This code will scrape the data from SpaceWeatherLive.com and print the first few rows of the DataFrame.
